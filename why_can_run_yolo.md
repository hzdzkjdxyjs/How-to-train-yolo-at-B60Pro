# Intel Arc Pro B60 训练 YOLO 架构分层图
 - 其实道理很简单，Intel的团队为了能让显卡运行大模型
 - 他们创建了torch.xpu的项目，使其可以调用各种算子，正是因为这个原因
 - 我们才可以使用它进行训练
```bash
┌───────────────────────────────────────────────────────────────────────────────┐
│                           YOLO 训练框架（Ultralytics）                         │
│-------------------------------------------------------------------------------│
│ - train.py / dataloader / loss / optimizer                                    │
│ - 通过 device='xpu' 选择 Intel GPU                                             │
│ - 调用 PyTorch 前端执行前向与反向传播                                           │
└───────────────────────────────────────────────────────────────────────────────┘

                                         ▼

┌───────────────────────────────────────────────────────────────────────────────┐
│                        PyTorch XPU 后端（torch.xpu）                           │
│-------------------------------------------------------------------------------│
│ - 将 YOLO 的 Conv / BN / SiLU / MatMul / NMS 转为 XPU Kernel                   │
│ - 管理 XPU Tensor（显存分配 / 调度 / 同步）                                     │
│ - 与 oneDNN 深度融合，加速卷积、归一化等算子                                     │
└───────────────────────────────────────────────────────────────────────────────┘

                                         ▼

┌───────────────────────────────────────────────────────────────────────────────┐
│                           oneAPI / oneDNN 优化层                               │
│-------------------------------------------------------------------------------│
│ - Kernel Fusion（如 Conv+BN+Activation）                                       │
│ - 自动选择 FP32 / BF16 / INT8 最优执行模式                                      │
│ - 内存 Layout 自动优化（NCHW ⇄ NHWC）                                          │
│ - Cache / SLM / 向量化加速                                                     │
└───────────────────────────────────────────────────────────────────────────────┘

                                         ▼

┌───────────────────────────────────────────────────────────────────────────────┐
│                            Level Zero Runtime 层                              │
│-------------------------------------------------------------------------------│
│ - Intel GPU 的底层 Runtime（类似 CUDA Runtime）                                 │
│ - USM/SLM 显存管理                                                             │
│ - 多引擎（Compute / Copy Engine）并行执行                                       │
│ - Command Queue → 调度到 GPU Tiles                                             │
│ - Tile 级负载均衡                                                              │
│ - xpu-smi 监控的就是这一层                                                     │
└───────────────────────────────────────────────────────────────────────────────┘

                                         ▼

┌───────────────────────────────────────────────────────────────────────────────┐
│                       Intel Arc Pro B60 GPU（硬件层）                          │
│-------------------------------------------------------------------------------│
│ - Xe Core：执行向量计算（Conv / MatMul）                                        │
│ - XMX：矩阵乘加加速器（等效 Tensor Core）                                        │
│ - SLM / L3 Cache：提升局部卷积、注意力性能                                       │
│ - GDDR6 显存：模型权重与特征图存储                                               │
│ - Pipeline 并行执行 YOLO 的 Conv / MatMul / Attention                          │
└───────────────────────────────────────────────────────────────────────────────┘


````
